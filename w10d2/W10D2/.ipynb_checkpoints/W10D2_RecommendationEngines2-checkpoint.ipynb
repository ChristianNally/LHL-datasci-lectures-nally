{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lighthouse Labs\n",
    "### W10D2 Recommendation Engines II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Agenda:**\n",
    "- Content-based Recommender Systems\n",
    "    - Item-to-item\n",
    "    - user-to-user\n",
    "    - Latent factors;\n",
    "    \n",
    "- Pros and Cons of different approaches to Recommenders\n",
    "- Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recommendation Systems\n",
    "\n",
    "- Two entities: **users** and **items**; \n",
    "    - whatever items may be: movies, books, musics, people, etc...;\n",
    "\n",
    "\n",
    "\n",
    "- Utility matrix: a matrix that captures the interaction between users and items; \n",
    "    - ratings, clicks, reviews, purchases;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ratings | Notting Hill | Jurassic Park | Rocky Balboa IV | Bird Box | Inglorious Basterds\n",
    "--------|--------------|---------------|-----------------|----------|----------------------\n",
    "User 1  |      ?       |      ?        |       2         |    ?     |    3 \n",
    "User 2  |      3       |      ?        |       ?         |    ?     |    ?\n",
    "User 3  |      ?       |      4        |       5         |    ?     |    5\n",
    "User 4  |      ?       |      ?        |       ?         |    ?     |    ?\n",
    "User 5  |      ?       |      ?        |       ?         |    5     |    ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Our main problem: _Sparsity_\n",
    "\n",
    "- The thing is: we cannot expect that users will interact with most items;\n",
    "    - Nobody has watched the whole (or the vast majority of the) catalogue of Netflix videos;\n",
    "        - Hopefully!\n",
    "    - Clients don't buy the majority of items in Amazon;\n",
    "    - Users don't listen to all the music in Spotify;\n",
    "    \n",
    "\n",
    "- Hence, the utility matrix usually has tons of missing data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What do we want?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Do we want to predict the missing ratings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Or do we want to find items that the users will enjoy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - Aren't these problems equivalent? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - We must carefully consider what we want, so we can properly train our model!\n",
    "     - but yes, our job for now is to try to fill **some** of the missing data in this matrix;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- There are different approaches to do so (which you learned yesterday): \n",
    "    - Content-based recommendations\n",
    "    - Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Content-based recommendation (Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Use knowledge of each item to recommend a similar one (item-based recommendation)\n",
    "\n",
    "- Based on the features of the items and users. For example\n",
    "    - movies: drama, comedy, horror, actors, director\n",
    "    - books: math, languages, author, year, etc...\n",
    "    - destinations: temperature, coast, mountains, price, distance, etc...\n",
    "    - users: age, location, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* If you read specific articles.\n",
    "* The representations of these articles as vectors will be similar to some other article representations as vectors.\n",
    "* A measure like cosine similarity is used to find similar articles.\n",
    "* These similar articles are then recommended to you if you haven’t read them to improve your engagement with the website or article medium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![img](img/CBF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Advantages\n",
    "\n",
    "- You don't need a lot of users to train your model.\n",
    "\n",
    "\n",
    "- Each user is modeled separately, so you might be able to capture uniqueness of taste.\n",
    "\n",
    "\n",
    "- Since you can obtain the features of the items, you can immediately recommend new items.\n",
    "\n",
    "\n",
    "- You can explain to the users why you are recommending an item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Disadvantages\n",
    "\n",
    "- Feature acquisition:\n",
    "    - What features should you use to explain the different ratings?\n",
    "    - Obtaining those features for each item might be very expensive. \n",
    "       <br>  <br>\n",
    "- Low diversity: hardly recommend an item outside the user's profile.\n",
    "    - What if a user has an eclectic taste?\n",
    " <br>  <br>\n",
    "- Cold start: you don't have any information about new users, what to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Collaborative Filtering: Memory Based Approach\n",
    "- User-user\n",
    "- Item-item\n",
    "- Latent-factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Memory-based collaborative filtering computes similarities between users or items and predicts a new rating for an item by taking the weighted average of ratings from the similar group. \n",
    "<br><br>\n",
    "\n",
    "- Use knowledge of a user’s past selections to recommend what similar users did (user-based recommendation).\n",
    "<br><br>\n",
    "- For item-based filtering: “users who preferred a certain item also liked…”\n",
    "<br><br>\n",
    "- The recommendations will be based on the utility matrix.\n",
    "<br><br>\n",
    "- The idea is to find similar items or similar users to make your recommendations, hence collaborative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ratings | Notting Hill | Jurassic Park | Rocky Balboa IV | Bird Box | Inglorious Basterds\n",
    "--------|--------------|---------------|-----------------|----------|----------------------\n",
    "User 1  |      ?       |      ?        |       2         |    ?     |    3 \n",
    "User 2  |      3       |      ?        |       ?         |    ?     |    ?\n",
    "User 3  |      ?       |      4        |       5         |    ?     |    5\n",
    "User 4  |      ?       |      ?        |       ?         |    ?     |    ?\n",
    "User 5  |      ?       |      ?        |       ?         |    5     |    ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### User-to-user\n",
    "\n",
    "User-based filtering first selects a user and finds users who have similar rating patterns. The recommender system then can suggest items that those similar users liked.\n",
    "\n",
    "* The process is to calculate the similarities between target user i and all other users, select the top X similar users, and take the weighted average of ratings from these X users with similarities as weights.\n",
    "<br><br>\n",
    "* While different people may have different baselines when giving ratings, some people tend to give high scores generally, some are pretty strict even though they are satisfied with items. To avoid this bias, we can subtract each user’s average rating of all items when computing weighted average, and add it back for target user.\n",
    "\n",
    "\n",
    "- Suppose you want to predict the rating that Sophie would give to Shrek.\n",
    "\n",
    "- Here is one approach:\n",
    "    1. Calculate the similarity of Sophie with each one of the users.\n",
    "    3. Next, select the $k$ users that are most similar to Sophie and also rated Shrek.\n",
    "    2. Aggregate their ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Item-to-item\n",
    "\n",
    "- Item-based filtering takes an item first and finds users who liked the particular item, then searches other items that those users also liked.\n",
    "\n",
    "- Item based collaborative filtering was introduced 1998 by Amazon. \n",
    "\n",
    "- Item based filtering looks at the similarity between different items, and does this by taking note of how many users that chose item X also chose item Y. \n",
    "\n",
    "- If the correlation is high enough, a similarity can be presumed to exist between the two items, and they can be assumed to be similar to one another.\n",
    "\n",
    "* E.g. Suppose you want to predict the rating that a user (Sophie) would give to a movie (Shrek)\n",
    "\n",
    "\n",
    "- Here is one approach:\n",
    "    1. Calculate the similarity between Shrek and each one of the movies in our matrix.\n",
    "    2. Next, select the $k$ movies that are  most similar to Shrek and that were also rated by Sophie.\n",
    "    3. Aggregate these ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating your recommender system (discussion)\n",
    "\n",
    "- Assessment of a recommender system can be very tricky;\n",
    "\n",
    "\n",
    "- Well, we can use the classical measures: mean squared error, mean absolute error;\n",
    "\n",
    "\n",
    "- But these error measures might be misleading;\n",
    "\n",
    "\n",
    "- What we actually want to measure is the interest that our user have on the recommended items;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Remember that:\n",
    "\n",
    "- Just training your model and evaluating it offline is not ideal.\n",
    "<br><br>\n",
    "\n",
    "\n",
    "- We don't have a ground truth! \n",
    "\n",
    "\n",
    "- Although we want to recommend only items the user is interested in, the recommended items might skew/affect the users interest;\n",
    "    - we can't measure this offline;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Because of this, one can argue that the best way of testing a recommender system is actually testing it for real (A/B test). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Besides...\n",
    "\n",
    "- The fact that a user liked a movie, it doesn't mean he/she wants to watch a similar movie in sequence;\n",
    "    - also hard to capture this offline;\n",
    "\n",
    "\n",
    "- Suppose a user likes action and sci-fi movies. \n",
    "\n",
    "\n",
    "- After just watching an action movie, should we recommend similar action movies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Diversity**: Our user is a Harry Potter fan, should we recommend HP1, HP2, HP3,...? We might want some diversity! To measure diversity you could user, for example,\n",
    "$$\n",
    "1 - \\bar{S}\n",
    "$$\n",
    "where $\\bar{S}$ is the average similarity of your recommendations; \n",
    "    - Careful though, you need a balance. Just going for diversity is pointless;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Novelty:** You want to indicate new items to your users or the most popular items? We need a balance here\n",
    "    - Just going for popular items won't surprise your users;\n",
    "    - Just going for new/unknown items affects the trust in your recommendation;\n",
    "        - Besides, popular items are popular for a reason;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Responsiveness:** how fast does your system change as new user/items interactions arrive? \n",
    "    - In other words, how frequently should you update your utility matrix?\n",
    "    \n",
    "    \n",
    "- **Persistence:** How long do you want to keep an item in your recommended list?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Non-algorithmic recommendations bias\n",
    "\n",
    "- There might be other reasons for you to recommend items;\n",
    "\n",
    "\n",
    "- For example, Netflix might want to stimulate original productions;\n",
    "\n",
    "\n",
    "- A company might want to favor a product with high profit margin;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Or you might want not recommend somethings\n",
    "\n",
    "- [Is Target the new pregnancy test?](https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/#4d7f597f6668)\n",
    "<br><br>\n",
    "- [Walmart links Martin Luther King Jr. to “Planet of the Apes”](http://www.nbcnews.com/id/10730202/ns/technology_and_science-tech_and_gadgets/t/wal-mart-blames-human-error-offensive-link/#.XEamRc2IaUk)\n",
    "<br><br>\n",
    "- BE CAREFUL WITH SENSITIVE MATTERS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Types of data\n",
    "\n",
    "- Explicit data: ratings, thumbs up, etc...\n",
    "\n",
    "\n",
    "- Implicit data: collected from your behaviour (e.g., mouse clicks, purchases, time spent doing something)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Users don't like to give explicit data\n",
    "    - so companies use different strategies: (tag your photo, 10 years challenge?)\n",
    "        - it is nice for you, so you do it;\n",
    "        - but it is also nice for them;\n",
    "        - Using these things without you knowing, is that ethical?\n",
    "        \n",
    "\n",
    "\n",
    "- Companies trust implicit data more, like time/money spent;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Based Collaborative Filtering\n",
    "\n",
    "Our task: decreases the dimension of the utility matrix A by extracting its latent factors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Latent factors\n",
    "- Latent factors are the characteristics of the items, for example, the genre of the music, the genre of the movie... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example of Matrix Factorization using PCA \n",
    "\n",
    "![img](img/0_pca.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We are going to do this using `Matrix Factorization` reducing the `Movie Ratings Matrix` into `Movies` and `Users Matrix`.\n",
    "\n",
    "These Matrices will be dense representations of the Movie Ratings Matrix.\n",
    "\n",
    "\n",
    "![img](img/SVD01.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How our data looks like?\n",
    "\n",
    "![img](img/SVD03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We've seen that if we had the user profile, we can learn the movie profile $\\hat{X}$ \n",
    "\n",
    "- Or if we had the movie profile, we could learn the user profile $\\hat{\\beta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We have a similar problem, but instead of minimizing on either $X$ or $\\beta$, we need to minimize on both!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visual SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Each movies has different genres like comedy and action with a specified rating precalculated.\n",
    "\n",
    "User also has a preference for these genres like ‘I like comedy or I dislike it’. Only the like score is added into the rating.\n",
    "\n",
    "![img](img/SVD04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We get a final rating matrix like so.\n",
    "\n",
    "Basically, the right matrix can be factorized into the 2 left matrices\n",
    "\n",
    "![img](img/SVD05.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We need to get target matrix on right decomposed into 2 matrices\n",
    "We need to find 2 matrices which when multiplied give us the target matrix\n",
    "How do we do this?\n",
    "\n",
    "![img](img/SVD06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We get a final rating matrix like so.\n",
    "\n",
    "Basically, the right matrix can be factorized into the 2 left matrices\n",
    "\n",
    "We start with random matrices and use gradient descent to find right values to get the correct target matrix\n",
    "\n",
    "![img](img/SVD07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As you can see we get 1.44 instead of 3\n",
    "This needs to be corrected.\n",
    "![img](img/SVD08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gradient descent will update values in the non target matrices.\n",
    "With enough iterations we will reach the right values.\n",
    "\n",
    "![img](img/SVD09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![img](img/SVD10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Same technique can be used to factorize empty target matrices as well.\n",
    "Thus we get right factored matrices from random ones.\n",
    "When multiplied these give ratings for all users.\n",
    "![img](img/SVD11.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
